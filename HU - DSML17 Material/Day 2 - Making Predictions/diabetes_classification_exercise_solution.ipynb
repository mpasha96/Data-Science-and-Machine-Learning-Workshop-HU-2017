{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas\n",
    "import numpy as np\n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the diabetes dataset\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "url = \"C:\\\\HU\\DSML Workshop\\\\Classification\\\\Hands-on\\\\pima-indians-diabetes_data.txt\"\n",
    "names = ['timespregnant', 'glucose', 'bp', 'skinfold','seruminsolin','bmi','pedigree','age','class']\n",
    "dataset = pandas.read_csv(url, names=names)\n",
    "\n",
    "# print the dimension of dataset\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look into your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# head\n",
    "print(dataset.head(20))\n",
    "\n",
    "# descriptions\n",
    "print(dataset.describe())\n",
    "\n",
    "# class distribution\n",
    "print(dataset.groupby('class').size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot scatter plot matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scatter plot matrix\n",
    "scatter_matrix(dataset)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patition the dataset into train (66%) and test (33%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(614, 8)\n",
      "(614,)\n",
      "(154, 8)\n",
      "(154,)\n"
     ]
    }
   ],
   "source": [
    "# Split-out validation dataset\n",
    "array = dataset.values\n",
    "X = array[:,0:dataset.shape[1]-1]\n",
    "Y = array[:,dataset.shape[1]-1]\n",
    "validation_size = 0.20\n",
    "seed = 7\n",
    "X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(X, Y, test_size=validation_size, random_state=seed)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "\n",
    "print(X_validation.shape)\n",
    "print(Y_validation.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn a decision tree classifier from training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with train-test split\n",
    "DT = DecisionTreeClassifier()\n",
    "DT.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  1.\n",
      "  0.  0.  1.  0.  1.  0.  0.  1.  0.  1.  1.  0.  0.  0.  0.  1.  0.  1.\n",
      "  1.  0.  1.  0.  1.  1.  1.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.\n",
      "  1.  1.  1.  0.  0.  0.  1.  1.  0.  1.  1.  1.  0.  1.  1.  0.  1.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.\n",
      "  1.  0.  1.  0.  1.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.\n",
      "  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.\n",
      "  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.\n",
      "  0.  1.  1.  0.  1.  0.  0.  1.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "predictions = DT.predict(X_validation)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evalutate Classifier accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.746753246753\n",
      "[[79 18]\n",
      " [21 36]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.81      0.80        97\n",
      "        1.0       0.67      0.63      0.65        57\n",
      "\n",
      "avg / total       0.74      0.75      0.75       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y_validation, predictions))\n",
    "print(confusion_matrix(Y_validation, predictions))\n",
    "print(classification_report(Y_validation, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform 10-fold cross validation and compute accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.67741935  0.5483871   0.67741935  0.74193548  0.61290323  0.70967742\n",
      "  0.67741935  0.74193548  0.74193548  0.74193548  0.58064516  0.70967742\n",
      "  0.61290323  0.80645161  0.66666667  0.8         0.66666667  0.63333333\n",
      "  0.66666667  0.8       ]\n",
      "0.690698924731\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation\n",
    "seed = 7\n",
    "scoring = 'accuracy'\n",
    "kfold = model_selection.KFold(n_splits=20, random_state=seed)\n",
    "cv_results = model_selection.cross_val_score(DT, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "print(cv_results)\n",
    "print(sum(cv_results)/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.776864 (0.060738)\n",
      "LDA: 0.773559 (0.058283)\n",
      "KNN: 0.710153 (0.064599)\n",
      "CART: 0.680883 (0.054520)\n",
      "NB: 0.750820 (0.050575)\n",
      "SVM: 0.656293 (0.044581)\n"
     ]
    }
   ],
   "source": [
    "# Test options and evaluation metric\n",
    "seed = 7\n",
    "scoring = 'accuracy'\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "cv_results = model_selection.cross_val_score(DT, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "\n",
    "\n",
    "# Spot Check Algorithms\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "    cv_results = model_selection.cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n",
    "    \n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
